"""
–¢–µ—Å—Ç—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—à–∏–±–æ–∫ Telegram –∏ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è markdown.
"""

import re


def parse_telegram_error(error_message: str) -> tuple[str | None, int | None]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –æ—Ç Telegram –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø entity –∏ byte offset.
    
    –ö–æ–ø–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ utils.py –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ –∏–º–ø–æ—Ä—Ç–∞ –≤—Å–µ–≥–æ –º–æ–¥—É–ª—è.
    """
    # –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ entity –Ω–∞ —Å–∏–º–≤–æ–ª—ã markdown
    entity_to_char = {
        'underline': '__',
        'bold': '*',
        'italic': '_',
        'strikethrough': '~',
        'code': '`',
        'spoiler': '||',
    }
    
    # –ò—â–µ–º —Ç–∏–ø entity –∏ byte offset
    # –ü–∞—Ç—Ç–µ—Ä–Ω: "Can't find end of <EntityType> entity at byte offset <number>"
    pattern = r"Can't find end of (\w+) entity at byte offset (\d+)"
    match = re.search(pattern, error_message, re.IGNORECASE)
    
    if match:
        entity_type = match.group(1).lower()
        byte_offset = int(match.group(2))
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å–∏–º–≤–æ–ª
        char = entity_to_char.get(entity_type)
        if char:
            return char, byte_offset
    
    return None, None


def fix_markdown_at_offset(text: str, problem_char: str, byte_offset: int) -> str:
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–æ–±–ª–µ–º–Ω—ã–π —Å–∏–º–≤–æ–ª markdown –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏.
    
    –ö–æ–ø–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ utils.py –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ –∏–º–ø–æ—Ä—Ç–∞ –≤—Å–µ–≥–æ –º–æ–¥—É–ª—è.
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º byte offset –≤ character offset
    text_bytes = text.encode('utf-8')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ offset –≤–∞–ª–∏–¥–Ω—ã–π
    if byte_offset >= len(text_bytes):
        byte_offset = len(text_bytes) - 1
    
    # –ù–∞—Ö–æ–¥–∏–º character offset —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π byte offset
    char_offset = len(text_bytes[:byte_offset].decode('utf-8', errors='ignore'))
    
    # –ò—â–µ–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è problem_char –≤ —Ç–µ–∫—Å—Ç–µ
    char_len = len(problem_char)
    positions = []
    i = 0
    while i <= len(text) - char_len:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω –ª–∏ —É–∂–µ
        if text[i:i+char_len] == problem_char and (i == 0 or text[i-1] != '\\'):
            positions.append(i)
        i += 1
    
    if not positions:
        # –ù–µ—Ç –≤—Ö–æ–∂–¥–µ–Ω–∏–π - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return text
    
    # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à—É—é –ø–æ–∑–∏—Ü–∏—é –∫ –ø—Ä–æ–±–ª–µ–º–Ω–æ–º—É offset
    closest_pos = min(positions, key=lambda p: abs(p - char_offset))
    
    # –¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä—ã: –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Å–∏–º–≤–æ–ª—ã
    
    def is_opening(pos: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–∏–º–≤–æ–ª –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–º —Ç–µ–≥–æ–º."""
        if pos + char_len > len(text):
            return False
        
        # –í –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
        if pos == 0:
            next_char = text[pos + char_len] if pos + char_len < len(text) else ''
            return next_char and next_char not in ' \n\t'
        
        prev_char = text[pos - 1]
        next_char = text[pos + char_len] if pos + char_len < len(text) else ''
        
        # –ü–æ—Å–ª–µ –ø—Ä–æ–±–µ–ª–∞/—Å–∫–æ–±–∫–∏ –∏ –ø–µ—Ä–µ–¥ –Ω–µ-–ø—Ä–æ–±–µ–ª–æ–º
        return prev_char in ' \n\t([{' and next_char and next_char not in ' \n\t'
    
    def is_closing(pos: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–∏–º–≤–æ–ª –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º —Ç–µ–≥–æ–º."""
        if pos + char_len > len(text):
            return False
        
        # –í –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
        if pos + char_len >= len(text):
            prev_char = text[pos - 1] if pos > 0 else ''
            return prev_char and prev_char not in ' \n\t'
        
        prev_char = text[pos - 1] if pos > 0 else ''
        next_char = text[pos + char_len]
        
        # –ü–æ—Å–ª–µ –Ω–µ-–ø—Ä–æ–±–µ–ª–∞ –∏ –ø–µ—Ä–µ–¥ –ø—Ä–æ–±–µ–ª–æ–º/–∑–Ω–∞–∫–æ–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è/–∫–æ–Ω—Ü–æ–º
        return (prev_char and prev_char not in ' \n\t' and
                (next_char in ' \n\t.!?,;:)]}' or pos + char_len == len(text)))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ –∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–∞—Ä—ã
    opening_positions = []
    closing_positions = []
    
    for pos in positions:
        if is_opening(pos):
            opening_positions.append(pos)
        elif is_closing(pos):
            closing_positions.append(pos)
    
    # –°–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–∞—Ä—ã: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–≥–æ –∏—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π
    paired = set()
    for open_pos in opening_positions:
        # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–≥–æ
        matching_close = None
        for close_pos in closing_positions:
            if close_pos > open_pos and close_pos not in paired:
                matching_close = close_pos
                break
        
        if matching_close:
            paired.add(open_pos)
            paired.add(matching_close)
    
    # –¢–µ–ø–µ—Ä—å –Ω–∞—Ö–æ–¥–∏–º –Ω–µ–ø–∞—Ä–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    unpaired = [pos for pos in positions if pos not in paired]
    
    if not unpaired:
        # –í—Å–µ —Å–∏–º–≤–æ–ª—ã –ø–∞—Ä–Ω—ã–µ, –Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –µ—Å—Ç—å –æ—à–∏–±–∫–∞
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∫ –ø—Ä–æ–±–ª–µ–º–Ω–æ–º—É offset
        pos_to_escape = closest_pos
    else:
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –Ω–µ–ø–∞—Ä–Ω—ã–π —Å–∏–º–≤–æ–ª –±–ª–∏–∂–∞–π—à–∏–π –∫ –ø—Ä–æ–±–ª–µ–º–Ω–æ–º—É offset
        pos_to_escape = min(unpaired, key=lambda p: abs(p - char_offset))
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ pos_to_escape
    return text[:pos_to_escape] + '\\' + text[pos_to_escape:]


class TestParseTelegramError:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ parse_telegram_error."""
    
    def test_parse_underline_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å Underline entity."""
        error = "Telegram server says - Bad Request: can't parse entities: Can't find end of Underline entity at byte offset 487"
        char, offset = parse_telegram_error(error)
        
        assert char == '__'
        assert offset == 487
    
    def test_parse_bold_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å Bold entity."""
        error = "Can't find end of Bold entity at byte offset 123"
        char, offset = parse_telegram_error(error)
        
        assert char == '*'
        assert offset == 123
    
    def test_parse_italic_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å Italic entity."""
        error = "Can't find end of Italic entity at byte offset 42"
        char, offset = parse_telegram_error(error)
        
        assert char == '_'
        assert offset == 42
    
    def test_parse_strikethrough_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å Strikethrough entity."""
        error = "Can't find end of Strikethrough entity at byte offset 100"
        char, offset = parse_telegram_error(error)
        
        assert char == '~'
        assert offset == 100
    
    def test_parse_code_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å Code entity."""
        error = "Can't find end of Code entity at byte offset 50"
        char, offset = parse_telegram_error(error)
        
        assert char == '`'
        assert offset == 50
    
    def test_parse_spoiler_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å Spoiler entity."""
        error = "Can't find end of Spoiler entity at byte offset 200"
        char, offset = parse_telegram_error(error)
        
        assert char == '||'
        assert offset == 200
    
    def test_parse_invalid_error(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–π –æ—à–∏–±–∫–∏."""
        error = "Some other error message"
        char, offset = parse_telegram_error(error)
        
        assert char is None
        assert offset is None
    
    def test_parse_unknown_entity(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ç–∏–ø–æ–º entity."""
        error = "Can't find end of UnknownEntity entity at byte offset 100"
        char, offset = parse_telegram_error(error)
        
        assert char is None
        assert offset is None


class TestFixMarkdownAtOffset:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ fix_markdown_at_offset."""
    
    def test_fix_unpaired_underscore_simple(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–ø–∞—Ä–Ω–æ–≥–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –≤ –ø—Ä–æ—Å—Ç–æ–º —Å–ª—É—á–∞–µ."""
        text = "–¢–µ–∫—Å—Ç —Å _–Ω–µ–ø–∞—Ä–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º"
        result = fix_markdown_at_offset(text, '_', 10)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π _ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\_' in result
    
    def test_fix_unpaired_underscore_in_middle(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–ø–∞—Ä–Ω–æ–≥–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞."""
        text = "–ù–∞—á–∞–ª–æ _–ø–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç_ –∏ _–Ω–µ–ø–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç"
        result = fix_markdown_at_offset(text, '_', 35)
        
        # –ü–µ—Ä–≤–∞—è –ø–∞—Ä–∞ –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞—Ç—å—Å—è, –≤—Ç–æ—Ä–æ–π _ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert result.count('_–ø–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç_') == 1
        assert result.count('\\_–Ω–µ–ø–∞—Ä–Ω—ã–π') == 1
    
    def test_fix_double_underscore_unpaired(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–ø–∞—Ä–Ω–æ–≥–æ –¥–≤–æ–π–Ω–æ–≥–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è."""
        text = "–¢–µ–∫—Å—Ç —Å __–Ω–µ–ø–∞—Ä–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º"
        result = fix_markdown_at_offset(text, '__', 10)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π __ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\__' in result
    
    def test_fix_asterisk_unpaired(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–ø–∞—Ä–Ω–æ–π –∑–≤–µ–∑–¥–æ—á–∫–∏ (bold)."""
        text = "–¢–µ–∫—Å—Ç —Å *–Ω–µ–ø–∞—Ä–Ω—ã–º bold"
        result = fix_markdown_at_offset(text, '*', 10)
        
        # –ù–µ–ø–∞—Ä–Ω–∞—è * –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞
        assert '\\*' in result
    
    def test_fix_tilde_unpaired(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–ø–∞—Ä–Ω–æ–π —Ç–∏–ª—å–¥—ã (strikethrough)."""
        text = "–¢–µ–∫—Å—Ç —Å ~–Ω–µ–ø–∞—Ä–Ω—ã–º strikethrough"
        result = fix_markdown_at_offset(text, '~', 10)
        
        # –ù–µ–ø–∞—Ä–Ω–∞—è ~ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞
        assert '\\~' in result
    
    def test_fix_with_utf8_characters(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º UTF-8 —Å–∏–º–≤–æ–ª–æ–≤."""
        # –†—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –∑–∞–Ω–∏–º–∞—é—Ç –±–æ–ª—å—à–µ –±–∞–π—Ç
        text = "–ü—Ä–∏–≤–µ—Ç _–Ω–µ–ø–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç"
        # "–ü—Ä–∏–≤–µ—Ç " = 7 —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ –≤ UTF-8 —ç—Ç–æ –±–æ–ª—å—à–µ –±–∞–π—Ç
        # –ü—Ä–∏–º–µ—Ä–Ω–æ 14 –±–∞–π—Ç (–∫–∞–∂–¥–∞—è —Ä—É—Å—Å–∫–∞—è –±—É–∫–≤–∞ –ø–æ 2 –±–∞–π—Ç–∞)
        result = fix_markdown_at_offset(text, '_', 14)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π _ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\_' in result
    
    def test_fix_with_emoji(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —ç–º–æ–¥–∑–∏."""
        text = "–¢–µ–∫—Å—Ç ü§î —Å _–Ω–µ–ø–∞—Ä–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º"
        # –≠–º–æ–¥–∑–∏ –∑–∞–Ω–∏–º–∞–µ—Ç 4 –±–∞–π—Ç–∞ –≤ UTF-8
        result = fix_markdown_at_offset(text, '_', 15)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π _ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\_' in result
    
    def test_fix_paired_symbols_not_touched(self):
        """–ü–∞—Ä–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã."""
        text = "_–ø–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç_ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç"
        # –£–∫–∞–∑—ã–≤–∞–µ–º offset –Ω–∞ –ø–∞—Ä–Ω—ã–π —Å–∏–º–≤–æ–ª
        result = fix_markdown_at_offset(text, '_', 0)
        
        # –ï—Å–ª–∏ –æ–±–∞ —Å–∏–º–≤–æ–ª–∞ –ø–∞—Ä–Ω—ã–µ, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å—Å—è
        # –∏–ª–∏ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–µ–ø–∞—Ä–Ω—ã–π
        assert '_–ø–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç_' in result or '\\_–ø–∞—Ä–Ω—ã–π' in result
    
    def test_fix_multiple_underscores(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è—Ö."""
        text = "_–ø–µ—Ä–≤—ã–π_ _–≤—Ç–æ—Ä–æ–π _—Ç—Ä–µ—Ç–∏–π"
        # –¢—Ä–µ—Ç–∏–π _ –Ω–µ–ø–∞—Ä–Ω—ã–π
        result = fix_markdown_at_offset(text, '_', 23)
        
        # –ü–µ—Ä–≤–∞—è –∏ –≤—Ç–æ—Ä–∞—è –ø–∞—Ä—ã –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è
        assert '_–ø–µ—Ä–≤—ã–π_' in result
        assert '_–≤—Ç–æ—Ä–æ–π' in result
        # –¢—Ä–µ—Ç–∏–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\_—Ç—Ä–µ—Ç–∏–π' in result or result.count('\\_') >= 1
    
    def test_fix_opening_underscore_rules(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª –¥–ª—è –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–≥–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è."""
        # –û—Ç–∫—Ä—ã–≤–∞—é—â–∏–π _ –∏–¥–µ—Ç –ø–æ—Å–ª–µ –ø—Ä–æ–±–µ–ª–∞ –∏ –ø–µ—Ä–µ–¥ —Å–ª–æ–≤–æ–º
        text = "–¢–µ–∫—Å—Ç _—Å–ª–æ–≤–æ –¥—Ä—É–≥–æ–π_—Ç–µ–∫—Å—Ç"
        # –¢—Ä–µ—Ç–∏–π _ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–º (–∏–¥–µ—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Å–ª–æ–≤–∞ –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞)
        result = fix_markdown_at_offset(text, '_', 20)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π _ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        # –§—É–Ω–∫—Ü–∏—è —ç–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—ã–π _ —Ç–∞–∫ –∫–∞–∫ —Ç—Ä–µ—Ç–∏–π –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ
        assert '\\_' in result
    
    def test_fix_closing_underscore_rules(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª –¥–ª—è –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è."""
        # –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–π _ –∏–¥–µ—Ç –ø–æ—Å–ª–µ —Å–ª–æ–≤–∞ –∏ –ø–µ—Ä–µ–¥ –ø—Ä–æ–±–µ–ª–æ–º
        text = "–¢–µ–∫—Å—Ç _—Å–ª–æ–≤–æ_ —á—Ç–æ_—Ç–æ –µ—â–µ"
        # –¢—Ä–µ—Ç–∏–π _ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º (–∏–¥–µ—Ç –ø–µ—Ä–µ–¥ —Å–ª–æ–≤–æ–º)
        result = fix_markdown_at_offset(text, '_', 18)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π _ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '—á—Ç–æ\\_—Ç–æ' in result or '\\_—Ç–æ' in result
    
    def test_fix_underscore_at_start(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏."""
        text = "_–Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ"
        result = fix_markdown_at_offset(text, '_', 0)
        
        # –ù–µ–ø–∞—Ä–Ω—ã–π _ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\_–Ω–∞—á–∞–ª–æ' in result
    
    def test_fix_underscore_at_end(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏."""
        text = "—Ç–µ–∫—Å—Ç –±–µ–∑ –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–≥–æ_"
        result = fix_markdown_at_offset(text, '_', len(text.encode('utf-8')) - 1)
        
        # –ï—Å–ª–∏ _ –Ω–∞ –∫–æ–Ω—Ü–µ –Ω–µ –ø–∞—Ä–Ω—ã–π, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '–æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–≥–æ\\_' in result or '\\_' in result
    
    def test_fix_empty_text(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        text = ""
        result = fix_markdown_at_offset(text, '_', 0)
        
        # –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è –ø—É—Å—Ç—ã–º
        assert result == ""
    
    def test_fix_no_problem_char(self):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–≥–¥–∞ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ."""
        text = "–û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Å–∏–º–≤–æ–ª–æ–≤ markdown"
        result = fix_markdown_at_offset(text, '_', 10)
        
        # –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        assert result == text
    
    def test_fix_already_escaped(self):
        """–£–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è."""
        text = "–¢–µ–∫—Å—Ç —Å —É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º \\_—Å–∏–º–≤–æ–ª–æ–º"
        result = fix_markdown_at_offset(text, '_', 30)
        
        # –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–≤–æ–π–Ω–æ–≥–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        assert '\\\\_' not in result
        assert '\\_—Å–∏–º–≤–æ–ª–æ–º' in result


class TestIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞."""
    
    def test_full_cycle_parse_and_fix(self):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –ø–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ."""
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–∏—Ç—É–∞—Ü–∏—é –∏–∑ –∑–∞–¥–∞—á–∏
        error = "Can't find end of Underline entity at byte offset 487"
        text = "–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç " * 30 + "__–Ω–∞—á–∞–ª–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –±–µ–∑ –∫–æ–Ω—Ü–∞"
        
        # –ü–∞—Ä—Å–∏–º –æ—à–∏–±–∫—É
        char, offset = parse_telegram_error(error)
        assert char == '__'
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
        fixed = fix_markdown_at_offset(text, char, offset)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–∏–º–≤–æ–ª —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\__' in fixed
    
    def test_multiple_fixes_needed(self):
        """–ù–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–ø–∞—Ä–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Ç—Ä–µ–±—É—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π."""
        error1 = "Can't find end of Italic entity at byte offset 10"
        text = "–¢–µ–∫—Å—Ç —Å _–ø–µ—Ä–≤—ã–º –∏ _–≤—Ç–æ—Ä—ã–º –Ω–µ–ø–∞—Ä–Ω—ã–º–∏"
        
        # –ü–µ—Ä–≤–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        char, offset = parse_telegram_error(error1)
        fixed1 = fix_markdown_at_offset(text, char, offset)
        
        # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –≤—Ç–æ—Ä–æ–µ
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω _ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω
        assert '\\_' in fixed1
    
    def test_multiple_sequential_errors(self):
        """
        –¢–µ—Å—Ç –¥–ª—è —Å–ª—É—á–∞—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –æ—à–∏–±–∫–∞–º–∏.
        –°–∏–º—É–ª–∏—Ä—É–µ—Ç —Å–∏—Ç—É–∞—Ü–∏—é –∫–æ–≥–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –Ω–µ–ø–∞—Ä–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤.
        """
        # –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏
        text = "–¢–µ–∫—Å—Ç —Å __–Ω–µ–ø–∞—Ä–Ω—ã–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ–º –∏ –µ—â–µ *–Ω–µ–ø–∞—Ä–Ω—ã–º –∂–∏—Ä–Ω—ã–º"
        
        # –ü–µ—Ä–≤–∞—è –æ—à–∏–±–∫–∞: Underline
        error1 = "Can't find end of Underline entity at byte offset 10"
        char1, offset1 = parse_telegram_error(error1)
        assert char1 == '__'
        
        fixed1 = fix_markdown_at_offset(text, char1, offset1)
        assert '\\__' in fixed1
        
        # –í—Ç–æ—Ä–∞—è –æ—à–∏–±–∫–∞: Bold (–ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–≤–æ–π)
        # Offset –∏–∑–º–µ–Ω–∏–ª—Å—è –∏–∑-–∑–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è \
        error2 = "Can't find end of Bold entity at byte offset 60"
        char2, offset2 = parse_telegram_error(error2)
        assert char2 == '*'
        
        fixed2 = fix_markdown_at_offset(fixed1, char2, offset2)
        assert '\\*' in fixed2
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±–∞ —Å–∏–º–≤–æ–ª–∞ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã
        assert '\\__' in fixed2
        assert '\\*' in fixed2
    
    def test_three_sequential_errors(self):
        """–¢–µ—Å—Ç —Å —Ç—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –æ—à–∏–±–∫–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤."""
        # –¢–µ–∫—Å—Ç —Å —Ç—Ä–µ–º—è —Ä–∞–∑–Ω—ã–º–∏ –Ω–µ–ø–∞—Ä–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
        text = "–ù–∞—á–∞–ª–æ _–∫—É—Ä—Å–∏–≤ –±–µ–∑ –∫–æ–Ω—Ü–∞, –ø–æ—Ç–æ–º *–∂–∏—Ä–Ω—ã–π –±–µ–∑ –∫–æ–Ω—Ü–∞, –∏ ~–∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–π –±–µ–∑ –∫–æ–Ω—Ü–∞"
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        current = text
        
        # –û—à–∏–±–∫–∞ 1: Italic
        char1, _ = parse_telegram_error("Can't find end of Italic entity at byte offset 7")
        current = fix_markdown_at_offset(current, char1, 7)
        assert '\\_' in current
        
        # –û—à–∏–±–∫–∞ 2: Bold
        char2, _ = parse_telegram_error("Can't find end of Bold entity at byte offset 40")
        current = fix_markdown_at_offset(current, char2, 40)
        assert '\\*' in current
        
        # –û—à–∏–±–∫–∞ 3: Strikethrough
        char3, _ = parse_telegram_error("Can't find end of Strikethrough entity at byte offset 70")
        current = fix_markdown_at_offset(current, char3, 70)
        assert '\\~' in current
        
        # –í—Å–µ —Ç—Ä–∏ —Å–∏–º–≤–æ–ª–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã
        assert '\\_' in current
        assert '\\*' in current
        assert '\\~' in current
    
    def test_complex_message_with_multiple_errors(self):
        """
        –†–µ–∞–ª—å–Ω—ã–π –∫–µ–π—Å: –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –Ω–µ–ø–∞—Ä–Ω—ã—Ö —Ç–µ–≥–æ–≤.
        """
        # –ò–º–∏—Ç–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç LLM —Å —Ä–∞–∑–Ω—ã–º–∏ markdown —Ç–µ–≥–∞–º–∏
        text = (
            "–ü—Ä–∏–≤–µ—Ç! –í–æ—Ç —Ç–≤–æ–π –æ—Ç–≤–µ—Ç:\n\n"
            "_–ü–µ—Ä–≤—ã–π –ø—É–Ω–∫—Ç –±–µ–∑ –∑–∞–∫—Ä—ã—Ç–∏—è\n"
            "–í—Ç–æ—Ä–æ–π –ø—É–Ω–∫—Ç —Å *–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∂–∏—Ä–Ω—ã–º*\n"
            "–¢—Ä–µ—Ç–∏–π –ø—É–Ω–∫—Ç —Å __–ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ–º –±–µ–∑ –∫–æ–Ω—Ü–∞\n"
            "–ò –µ—â–µ —Ç–µ–∫—Å—Ç —Å ~–∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–º –±–µ–∑ –∑–∞–∫—Ä—ã—Ç–∏—è"
        )
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏
        current = text
        errors_fixed = 0
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–æ 7 –ø–æ–ø—ã—Ç–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        test_errors = [
            ("Can't find end of Italic entity at byte offset 35", '_', 35),
            ("Can't find end of Underline entity at byte offset 120", '__', 120),
            ("Can't find end of Strikethrough entity at byte offset 180", '~', 180),
        ]
        
        for error_msg, expected_char, offset in test_errors:
            char, parsed_offset = parse_telegram_error(error_msg)
            assert char == expected_char
            
            current = fix_markdown_at_offset(current, char, offset)
            errors_fixed += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Å–∏–º–≤–æ–ª—ã —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã
        assert errors_fixed == 3
        assert current.count('\\_') >= 1  # –ú–∏–Ω–∏–º—É–º –æ–¥–∏–Ω —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π _
        assert current.count('\\__') >= 1  # –ú–∏–Ω–∏–º—É–º –æ–¥–∏–Ω —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π __
        assert current.count('\\~') >= 1  # –ú–∏–Ω–∏–º—É–º –æ–¥–∏–Ω —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ~

